
{
    "app_title": "Markov Chains Interactive Learning",
    "app_title_short": "Interactive Markov Chains",
    "welcome": "Welcome",
    "login_prompt": "Login to start your journey into Markov Chains.",
    "login_admin_hint": "(Try 'admin' for the admin view)",
    "username_placeholder": "Username (e.g., learner, admin)",
    "password_placeholder": "Password (any password will work)",
    "sign_in": "Sign in",
    "welcome_user": "Welcome, {username}",
    "logout": "Logout",
    "learner": "Learner",
    "admin": "Admin",
    "dashboard_title": "Explore Markov Chains",
    "dashboard_subtitle": "Select a demonstration or experiment to begin.",
    "back_to_dashboard": "Back to Dashboard",
    "simulation_controls": "Simulation Controls",
    "step_once": "Step Once",
    "run_10_steps": "Run 10 Steps",
    "run_100_steps": "Run 100 Steps",
    "reset": "Reset",
    "tooltip_step_once": "Advance the simulation by a single step.",
    "tooltip_run_10_steps": "Run 10 simulation steps in quick succession.",
    "tooltip_run_100_steps": "Run 100 simulation steps to see long-term trends.",
    "tooltip_reset": "Reset the simulation to its initial state.",
    "statistics": "Statistics",
    "current_state": "Current State",
    "total_steps": "Total Steps",
    "state_counts": "State Counts",
    "admin_panel_title": "Admin Panel",
    "admin_panel_subtitle": "Create a new learning experiment.",
    "form_title": "Title",
    "form_prerequisites": "Prerequisites (comma-separated)",
    "form_description": "Description",
    "form_guide_text": "Guide Text",
    "form_nodes_json": "Nodes (JSON Array)",
    "form_matrix_json": "Transition Matrix (JSON Object)",
    "form_initial_state": "Initial State ID",
    "create_experiment": "Create Experiment",
    "error_invalid_config": "Invalid JSON or configuration",
    "error_unknown": "An unknown error occurred.",
    "error_nodes_json": "Nodes JSON must be a non-empty array.",
    "error_matrix_json": "Matrix JSON must be an object.",
    "error_initial_state": "Initial state must be one of the defined node IDs.",
    "exp_weather_title": "Introduction: Weather Prediction",
    "exp_weather_desc": "A simple model to predict tomorrow's weather. Learn the basics of states and transition probabilities.",
    "exp_weather_guide": "This is a classic Markov Chain example. We have two states: 'Sunny' and 'Rainy'. The arrows show the probability of transitioning from one state to another. For example, if it is Sunny today, there is a 90% chance it will be Sunny tomorrow. Press 'Step' to simulate one day at a time and see how the state changes. Observe the 'State Counts' to see the long-term distribution.",
    "exp_walk_title": "The Drunkard's Walk",
    "exp_walk_desc": "A one-dimensional random walk. Explore concepts like recurrence and expected position.",
    "exp_walk_guide": "Imagine a person walking on a line, taking a step left or right with equal probability. This is a 'random walk'. In this model, we have 5 possible positions. Notice the 'boundary' states (A and E). From these, the person can only move in one direction (back towards the center). What do you think will happen over many steps? This concept is foundational in physics and finance.",
    "exp_brand_title": "Marketing: Brand Loyalty",
    "exp_brand_desc": "Model how customers switch between two competing brands over time.",
    "exp_brand_guide": "Businesses use Markov chains to model customer loyalty. Here, we have two brands, 'AlphaCola' and 'BetaDrink'. The probabilities represent the chance a customer who bought one brand today will switch to the other for their next purchase. Run the simulation for many steps (e.g., 1000) to find the 'steady-state' or 'market share' for each brand. This shows the long-term equilibrium.",
    "exp_entropy_title": "Advanced: Ergodicity & Entropy",
    "exp_entropy_desc": "Explore a system that visits every state and understand how information is measured.",
    "exp_entropy_guide": "This system is 'ergodic', meaning that from any state, it's possible to eventually reach any other state. Over time, the system will settle into a predictable distribution of states, regardless of where it started. The concept of Entropy in information theory, related to this, measures the average uncertainty or 'surprise' of the outcome. A highly predictable system has low entropy."
}